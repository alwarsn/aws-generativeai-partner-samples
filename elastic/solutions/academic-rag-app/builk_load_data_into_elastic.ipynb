{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8986853fc9ec184d",
   "metadata": {},
   "source": [
    "## Bulk Upload PDF data into Elastic\n",
    "\n",
    "#### Introduction\n",
    "In this module we are going to bulk upload documents into Elastic. Check out the folder \"inputs\" to see the different pdf files we will be ingesting. We have a range of documents such as academic, admissions, financial, student services, and graduation pdf files.\n",
    "\n",
    "#### Use Case\n",
    "There are many ways to bring data into Elastic. We have already used the Elastic UI to upload a document, but what if we need to uplodad multiple documents? In this module we will use the bulk uploader, to upload multiple pdf documents all at once.  \n",
    "\n",
    "#### Implementation\n",
    "In steps 1,2,3 we are going to create an Elastic index, index mapping, and ingest pipeline which will be used to store data into Elastic in the proper format. We are also going to use our inference endpoint to create our sparse embedding, on our pdf data so that we can use semantic search against that data in a RAG application. The semantic_text field type automatically generates embeddings for text content using an inference endpoint. Long passages are automatically chunked to smaller sections to enable the processing of larger corpuses of text. This mapping type was designed to simplify common challenges of building a RAG application and brings together the steps of chunking text, generating embeddings, and then retrieving them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecd6156eaac17c9",
   "metadata": {},
   "source": [
    "#### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5939a6c8475e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install requests --force-reinstall --quiet\n",
    "%pip install StringIO --force-reinstall --quiet\n",
    "%pip install dotenv --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e5ab855ad2ec3e",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981795830c829d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import logging\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import requests\n",
    "from io import StringIO\n",
    "from dotenv import load_dotenv\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7bad77c588c665",
   "metadata": {},
   "source": [
    "#### Setup connections to Elastic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Elastic Cloud ID:  ········\n",
      "Elastic Api Key:  ········\n"
     ]
    }
   ],
   "source": [
    "#load_dotenv(stream=StringIO(requests.get('http://kubernetes-vm:9000/env').text))\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(module)s:%(lineno)d - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# Initialize the Elasticsearch client\n",
    "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
    "ELASTIC_API_KEY = getpass(\"Elastic Api Key: \")\n",
    "\n",
    "logging.debug(f'ELASTIC_CLOUD_ID {ELASTIC_CLOUD_ID}')\n",
    "logging.debug(f'ELASTIC_API_KEY: {ELASTIC_API_KEY}')\n",
    "\n",
    "\n",
    "# Create the client instance\n",
    "es = Elasticsearch(\n",
    "    # For local development\n",
    "    # hosts=[\"http://localhost:9200\"]\n",
    "    cloud_id=ELASTIC_CLOUD_ID,\n",
    "    api_key=ELASTIC_API_KEY,\n",
    "        request_timeout=120,\n",
    "        retry_on_timeout=True,\n",
    "        max_retries=3\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Test Elastic Connection",
   "id": "cf14d497c96c56f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(es.info())",
   "id": "3664d4572183ad27"
  },
  {
   "cell_type": "markdown",
   "id": "940ca8381b45f4e8",
   "metadata": {},
   "source": [
    "#### 1) Create Elastic index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f75e71db6cf195",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'academic_documents'\n",
    "pipeline_id = 'attachment'\n",
    "pdf_dir = 'inputs'\n",
    "\n",
    "# 1. Delete the old index (if it exists)\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7d5987a6992b44",
   "metadata": {},
   "source": [
    "#### 2) Create the index with the correct mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2524305bc024cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"attachment\": {\n",
    "                \"properties\": {\n",
    "                    \"content\": {\n",
    "                        \"type\": \"text\",\n",
    "                        \"fields\": {\n",
    "                            \"keyword\": {\n",
    "                                \"type\": \"keyword\",\n",
    "                                \"ignore_above\": 256\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"semantic_content\": {\n",
    "                \"type\": \"semantic_text\",\n",
    "                \"inference_id\": \".elser-2-elasticsearch\",\n",
    "                \"model_settings\": {\n",
    "                    \"task_type\": \"sparse_embedding\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es.indices.create(index=index_name, body=mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f38cc8bd71cef0",
   "metadata": {},
   "source": [
    "####  3) Create the ingest pipeline (attachment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5774400eb1c9c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_def = {\n",
    "    \"description\": \"Extract attachment information\",\n",
    "    \"processors\": [\n",
    "        {\n",
    "            \"attachment\": {\n",
    "                \"field\": \"data\",\n",
    "                \"remove_binary\": True\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"set\": {\n",
    "                \"field\": \"semantic_content\",\n",
    "                \"value\": \"{{attachment.content}}\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "es.ingest.put_pipeline(id=pipeline_id, body=pipeline_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ebe42ce1544a56",
   "metadata": {},
   "source": [
    "####  4) Read and encode PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2ef8200384c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_base64(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        return base64.b64encode(file.read()).decode('utf-8')\n",
    "\n",
    "def generate_actions(pdf_dir):\n",
    "    for filename in os.listdir(pdf_dir):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            file_path = os.path.join(pdf_dir, filename)\n",
    "            logging.info(f\"Processing file: {file_path}\")\n",
    "            base64_encoded = convert_pdf_to_base64(file_path)\n",
    "            yield {\n",
    "                \"_op_type\": \"index\",\n",
    "                \"_index\": index_name,\n",
    "                \"_source\": {\n",
    "                    \"data\": base64_encoded\n",
    "                },\n",
    "                \"pipeline\": pipeline_id\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde9cc5ed34a49ec",
   "metadata": {},
   "source": [
    "#### 5) Upload the documents using the ingest pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f804b844d085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.bulk(es, generate_actions(pdf_dir))\n",
    "\n",
    "logging.info(\"Finished indexing PDF documents.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 6) Check out your PDF Documents in Elastic\n",
    "\n",
    "Now that we have bulk uploaded our pdfs into Elastic, let's take a look at those documents in the Discover.\n",
    "\n",
    "Within the Elastic console, click on the hamburger icon in the top left, scroll down to the bottom, click \"Stack Management\", click \"Index Management\", select \"academic_documents\", click the blue icon \"View in Discover\". Now you can see your index, fields, values, and your semantic embeddings. <br> <br>\n",
    "\n",
    "\n",
    "<img src=\"static/discover2.gif\" alt=\"discover\" width=\"1920\"/>\n",
    "\n",
    " "
   ],
   "id": "fe3b4acfc30532bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 7) Optional - Ask Questions in Playground\n",
    "In the Elastic console navigate to the Playground. Then select \"academic_documents\" as your index and ask a few questions about your data?\n",
    "for example: \n",
    "\n",
    "* What is the price difference for college courses between florida residents and non-florida residents?\n",
    "* What does my GPA need to be in order to graduate with honors?\n",
    "* Can I register for courses in person?\n"
   ],
   "id": "697479fa4ed45563"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
