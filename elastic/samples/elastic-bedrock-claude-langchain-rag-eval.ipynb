{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Evaluate Retrieval Augmented Generation with Elastic, Anthropic Claude 3, Amazon Bedrock, Langchain and RAGAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook we will show you how to use Langchain, Anthropic Claude 3, Elastic and RAGAS to build and evaluate response of a Retrieval Augmented Generation (RAG) solution\n",
    "\n",
    "\n",
    "#### Use case\n",
    "\n",
    "Evaluation of RAG (Retrieval-Augmented Generation) Application for Private Documentation Question Answering \n",
    "\n",
    "\n",
    "#### Persona\n",
    "As an analyst at Anycompany, Bob wants to evaluate the response of a Retrieval-Augmented Generation (RAG) application for answering questions based on the company's private documentation. The RAG application combines information retrieval and language generation techniques to provide accurate and relevant answers to users' questions. \n",
    "\n",
    "#### Implementation\n",
    "To fulfill this use case, in this notebook we will show how to evaluate a RAG Application to answer questions from business data. We will use the Anthropic Claude 3 Sonnet Foundation model, Elastic, Langchain and RAGAS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python 3.10\n",
    "\n",
    "⚠  For this lab we need to run the notebook based on a Python 3.10 runtime. ⚠\n",
    "\n",
    "\n",
    "## Installation\n",
    "\n",
    "To run this notebook you would need to install dependencies - boto3, botocore, elasticsearch and langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.11/site-packages (24.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.33.13 requires botocore==1.34.131, but you have botocore 1.35.76 which is incompatible.\n",
      "sagemaker 2.224.1 requires attrs<24,>=23.1.0, but you have attrs 24.2.0 which is incompatible.\n",
      "sagemaker 2.224.1 requires numpy<2.0,>=1.9.0, but you have numpy 2.1.3 which is incompatible.\n",
      "sagemaker 2.224.1 requires protobuf<5.0,>=3.12, but you have protobuf 5.29.1 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.6.0 which is incompatible.\n",
      "langchain-aws 0.2.9 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.33.13 requires botocore==1.34.131, but you have botocore 1.35.76 which is incompatible.\n",
      "sagemaker 2.224.1 requires attrs<24,>=23.1.0, but you have attrs 24.2.0 which is incompatible.\n",
      "sagemaker 2.224.1 requires numpy<2.0,>=1.9.0, but you have numpy 2.1.3 which is incompatible.\n",
      "sagemaker 2.224.1 requires protobuf<5.0,>=3.12, but you have protobuf 5.29.1 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.33.13 requires botocore==1.34.131, but you have botocore 1.35.76 which is incompatible.\n",
      "sagemaker 2.224.1 requires attrs<24,>=23.1.0, but you have attrs 24.2.0 which is incompatible.\n",
      "sagemaker 2.224.1 requires protobuf<5.0,>=3.12, but you have protobuf 5.29.1 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.33.13 requires botocore==1.34.131, but you have botocore 1.35.76 which is incompatible.\n",
      "sagemaker 2.224.1 requires attrs<24,>=23.1.0, but you have attrs 24.2.0 which is incompatible.\n",
      "sagemaker 2.224.1 requires protobuf<5.0,>=3.12, but you have protobuf 5.29.1 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.33.13 requires botocore==1.34.131, but you have botocore 1.35.76 which is incompatible.\n",
      "sagemaker 2.224.1 requires attrs<24,>=23.1.0, but you have attrs 24.2.0 which is incompatible.\n",
      "sagemaker 2.224.1 requires numpy<2.0,>=1.9.0, but you have numpy 2.1.3 which is incompatible.\n",
      "sagemaker 2.224.1 requires protobuf<5.0,>=3.12, but you have protobuf 5.29.1 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.6.0 which is incompatible.\n",
      "langchain 0.3.9 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.1.3 which is incompatible.\n",
      "langchain-community 0.3.9 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.1.3 which is incompatible.\n",
      "langchain-aws 0.2.9 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sagemaker 2.224.1 requires attrs<24,>=23.1.0, but you have attrs 24.2.0 which is incompatible.\n",
      "sagemaker 2.224.1 requires numpy<2.0,>=1.9.0, but you have numpy 2.1.3 which is incompatible.\n",
      "sagemaker 2.224.1 requires protobuf<5.0,>=3.12, but you have protobuf 5.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.33.13 requires botocore==1.34.131, but you have botocore 1.35.76 which is incompatible.\n",
      "sagemaker 2.224.1 requires attrs<24,>=23.1.0, but you have attrs 24.2.0 which is incompatible.\n",
      "sagemaker 2.224.1 requires protobuf<5.0,>=3.12, but you have protobuf 5.29.1 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install boto3 --force-reinstall --quiet\n",
    "%pip install botocore --force-reinstall --quiet\n",
    "%pip install langchain --force-reinstall --quiet\n",
    "%pip install langchain-aws --force-reinstall --quiet\n",
    "%pip install langchain-elasticsearch --force-reinstall --quiet\n",
    "%pip install elasticsearch --force-reinstall --quiet\n",
    "%pip install pypdf --force-reinstall --quiet\n",
    "%pip install ragas==0.2.6 --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Restart\n",
    "\n",
    "Restart the kernel with the updated packages that are installed through the dependencies above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Setup \n",
    "\n",
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import botocore\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_aws import AmazonKnowledgeBasesRetriever\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from botocore.client import Config\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from elasticsearch import Elasticsearch\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.chains import RetrievalQA\n",
    "from getpass import getpass\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Initialization\n",
    "\n",
    "Initiate Bedrock Runtime and BedrockChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "\n",
    "modelId = 'anthropic.claude-3-sonnet-20240229-v1:0' # change this to use a different version from the model provider\n",
    "embeddingmodelId = 'amazon.titan-embed-text-v1' # change this to use a different embedding model\n",
    "\n",
    "llm = ChatBedrockConverse(model_id=modelId, client=bedrock_client)\n",
    "embeddings = BedrockEmbeddings(model_id=embeddingmodelId,client=bedrock_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files from directory\n",
    "\n",
    "Load all PDF files which are present in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TMP_DIR = os.path.join(os.path.dirname(os.path.realpath('__file__')), 'media/2018-SaoE-Enhancing_the_Simulation_of_Complex_Mechanical_Systems_with_Machine_Learning.pdf')\n",
    "loader = PyPDFLoader(TMP_DIR)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Documents\n",
    "\n",
    "Chunk documents into passages in order to improve the retrieval specificity and to ensure that we can provide multiple passages within the context window of the final question answering prompt.\n",
    "\n",
    "Here we are chunking documents into 1000 token passages with an overlap of 0 tokens.\n",
    "\n",
    "Here we are using Recursive Character Text splitter but Langchain offers more advanced splitters to reduce the chance of context being lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=['\\n\\n', '\\n', '.', ','],\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=0\n",
    "        )\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Elasticsearch\n",
    "\n",
    "We'll use the Cloud ID to identify our deployment, because we are using Elastic Cloud deployment. To find the Cloud ID for your deployment, go to [Cloud ID](https://cloud.elastic.co/deployments) and select your deployment.\n",
    "\n",
    "We will use ElasticsearchStore to connect to our elastic cloud deployment. This would help create and index data easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Elastic deployment Cloud ID:  ········\n",
      "Elastic deployment API Key:  ········\n"
     ]
    }
   ],
   "source": [
    "cloud_id = getpass(\"Elastic deployment Cloud ID: \")\n",
    "cloud_api_key = getpass(\"Elastic deployment API Key: \")\n",
    "index_name= \"new-index-1\"\n",
    "\n",
    "vector_store = ElasticsearchStore(\n",
    "        es_cloud_id=cloud_id,  \n",
    "        index_name= index_name, \n",
    "        embedding=embeddings,\n",
    "        es_api_key=cloud_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index data into Elasticsearch and initialize retriever\n",
    "\n",
    "Next, we will index data to elasticsearch using ElasticsearchStore.from_documents. We will use Cloud ID, Password and Index name values set in the Create cloud deployment step. We will set embedding to BedrockEmbeddings to embed the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectordb = vector_store.from_documents(\n",
    "        texts, \n",
    "        embeddings,\n",
    "        index_name=index_name,\n",
    "        es_cloud_id=cloud_id,\n",
    "        es_api_key=cloud_api_key\n",
    "        )\n",
    "\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Invocation and Response Generation using RetrievalQA chain\n",
    "\n",
    "Now that we have the passages stored in Elasticsearch and LLM is initialized, we can now ask a question to get the relevant passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is a tool that allows predictions about future behavior to be drawn from existing data sets. It is used in a wide variety of applications, from spam filters to self-driving cars. While machine learning has been around for decades, it has seen a surge in popularity and capabilities in recent years due to increases in computing power and the development of user-friendly software toolkits in various programming languages.\n",
      "\n",
      "Machine learning typically involves three main steps:\n",
      "\n",
      "1. Framing the problem: Determining the question you want to answer, the data required to answer it, and how to collect that data.\n",
      "\n",
      "2. Training an algorithm: Providing an appropriately formatted dataset and selecting the algorithm and parameter values to train a model that can make predictions or decisions based on new data inputs.\n",
      "\n",
      "3. Evaluating the model: Splitting the data into training and test sets, using the training data to build the model, and evaluating its performance on the test data to assess its prediction accuracy.\n",
      "\n",
      "The context provided does not go into deep theoretical details of machine learning, but it introduces the key concepts necessary to understand the implementation described. Machine learning has great potential for assisting and working alongside techniques like finite element analysis in mechanical systems and engineering applications. I would be happy to provide more details or discuss specific use cases related to applying machine learning to mechanical systems. Please let me know if you have any other questions!\n",
      "\n",
      "</response>\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Machine learning?\"\n",
    "\n",
    "\n",
    "machinelearning_advisor_template = \"\"\"\n",
    "    Human: You will be acting as a Machine Learning advisor on complex Mechanical systems named Poly created by the company Polymath. \n",
    "    Your goal is to give advice related to Application of Machine Learning on Mechanical Systems to users. You will be replying to users \n",
    "    who are asking questions on Application of Machine Learning in Mechanical Systems \n",
    "    site and who will be confused if you don't respond in the character of Poly.\n",
    "    \n",
    "    You should maintain a friendly customer service tone.\n",
    "\n",
    "    Here is the document you should reference when answering the user: <context>{context}</context>\n",
    "\n",
    "    Here are some important rules for the interaction:\n",
    "    - Always stay in character, as Poly, a Machine Learning advisor on complex Mechanical systems\n",
    "    - If you are unsure how to respond, say “Sorry, I didn’t understand that. Could you repeat the question?”\n",
    "    - If someone asks something irrelevant, say, “Sorry, I am Poly and I give career advice. Do you have a question related to Application of Machine Learning in Mechanical Systems today I can help you with?”\n",
    "\n",
    "    Here is an example of how to respond in a standard interaction:\n",
    "\n",
    "    <example>\n",
    "    User: Hi, how were you created and what do you do?\n",
    "    Poly: Hello! My name is Poly, and I was created by Polymath  to give advice on Application of Machine Learning in Mechanical Systems. \n",
    "        What can I help you with today?\n",
    "    User: Hi, how can I use Decision Trees?\n",
    "    Poly: The method for using decision trees described in the given context is to first rank all\n",
    "        all the rules within the decision tree to find the most meaningful and reliable design subspaces.\n",
    "        Then, determine how many significant rules exist within the dataset to present the engineer\n",
    "        with the most reliable and important knowledge. Finally, use the resulting rules from the decision tree\n",
    "        to make predictions or decisions based on the given target variable.\n",
    "        User: Hi, What is Machine Learning?\n",
    "    Poly: Machine learning is a tool that allows predictions about future behavior to be drawn from existing\n",
    "        data sets. It is used in everything from spam filters to self-driving cars. While the field has been\n",
    "        around for decades, it has flourished over the last several years as computing power has increased\n",
    "        and user-friendly toolkits have been developed in a variety of programming languages. We do not\n",
    "        go into detail on machine learning theory and practice in this paper, but we do introduce the\n",
    "        concepts necessary for understanding our implementation of it.\n",
    "    </example>\n",
    "\n",
    "    Here is the user’s question: <question> {question} </question>\n",
    "\n",
    "    How do you respond to the user’s question?\n",
    "    Think about your answer first before you respond. Put your response in <response></response> tags.\n",
    "    Assistant: <response>\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=machinelearning_advisor_template, input_variables=[\"context\",\"question\"])\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\",retriever=retriever, return_source_documents=True, chain_type_kwargs={\"prompt\": prompt})\n",
    "response = qa_chain.invoke(query)\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Evaluation Data\n",
    "\n",
    "As RAGAS aims to be a reference-free evaluation framework, the required preparations of the evaluation dataset are minimal. You will need to prepare `questions` and `reference` pairs from which you can prepare the remaining information through inference as shown below. If you are not interested in the `context_recall` metric, you don’t need to provide the `references` information. In this case, all you need to prepare are the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ragas import SingleTurnSample, EvaluationDataset\n",
    "\n",
    "questions = [\"What is first step in machine learning metamodel?\", \n",
    "             \"What is the final step in machine learning metamodel?\"]\n",
    "\n",
    "references = [\"The first step in machine learning is framing the problem\",\n",
    "                 \"The final step in machine learning is verification\"]\n",
    "\n",
    "samples = []\n",
    "\n",
    "for idx, query in enumerate(questions):\n",
    "    samples.append(\n",
    "        SingleTurnSample(\n",
    "            user_input=query,\n",
    "            retrieved_contexts=[docs.page_content for docs in retriever.invoke(query)],\n",
    "            response=qa_chain.invoke(query)[\"result\"],\n",
    "            reference=references[idx]\n",
    "        )\n",
    "    )\n",
    "\n",
    "dataset = EvaluationDataset(samples=samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the RAG application\n",
    "\n",
    "First, import all the metrics you want to use from `ragas.metrics`. Then, you can use the `evaluate()` function and simply pass in the relevant metrics and the prepared dataset. Below is a brief description of the metrics\n",
    "\n",
    "* **Faithfulness**: This measures the factual consistency of the generated answer against the given context. It is calculated from answer and retrieved context. The answer is scaled to (0,1) range. Higher the better.\n",
    "* **Response Relevance**: The evaluation metric, Response Relevancy, focuses on assessing how pertinent the generated answer is to the given prompt. A lower score is assigned to answers that are incomplete or contain redundant information and higher scores indicate better relevancy. This metric is computed using the question, the context and the answer. Please note, that eventhough in practice the score will range between 0 and 1 most of the time, this is not mathematically guaranteed, due to the nature of the cosine similarity ranging from -1 to 1.\n",
    "* **Context Precision**: Context Precision is a metric that evaluates whether all of the ground-truth relevant items present in the contexts are ranked higher or not. Ideally all the relevant chunks must appear at the top ranks. This metric is computed using the question, ground_truth and the contexts, with values ranging between 0 and 1, where higher scores indicate better precision.\n",
    "* **Context Recall**: Context recall measures the extent to which the retrieved context aligns with the annotated answer, treated as the ground truth. It is computed based on the ground truth and the retrieved context, and the values range between 0 and 1, with higher values indicating better performance.\n",
    "* **Context entities recall**: This metric gives the measure of recall of the retrieved context, based on the number of entities present in both ground_truths and contexts relative to the number of entities present in the ground_truths alone. Simply put, it is a measure of what fraction of entities are recalled from ground_truths. This metric is useful in fact-based use cases like tourism help desk, historical QA, etc. This metric can help evaluate the retrieval mechanism for entities, based on comparison with entities present in ground_truths, because in cases where entities matter, we need the contexts which cover them.\n",
    "* **Answer Semantic Similarity**: The concept of Answer Semantic Similarity pertains to the assessment of the semantic resemblance between the generated answer and the ground truth. This evaluation is based on the ground truth and the answer, with values falling within the range of 0 to 1. A higher score signifies a better alignment between the generated answer and the ground truth.\n",
    "* **Answer Correctness**: The assessment of Answer Correctness involves gauging the accuracy of the generated answer when compared to the ground truth. This evaluation relies on the ground truth and the answer, with scores ranging from 0 to 1. A higher score indicates a closer alignment between the generated answer and the ground truth, signifying better correctness. Answer correctness encompasses two critical aspects: semantic similarity between the generated answer and the ground truth, as well as factual similarity. These aspects are combined using a weighted scheme to formulate the answer correctness score. Users also have the option to employ a ‘threshold’ value to round the resulting score to binary, if desired.\n",
    "* **Aspect Critique**: This is designed to assess submissions based on predefined aspects such as harmlessness, maliciousness, coherence, and conciseness. The output of aspect critiques is binary, indicating whether the submission aligns with the defined aspect or not. This evaluation is performed using the ‘answer’ as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf2d35050a24c468c56048d72133480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>llm_context_precision_with_reference</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>harmfulness</th>\n",
       "      <th>maliciousness</th>\n",
       "      <th>coherence</th>\n",
       "      <th>conciseness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is first step in machine learning metamodel?</td>\n",
       "      <td>[variety of ways to produce models that use the best parts of multiple algorithms. Most popular \\nalgorithms are available in preprogrammed toolkits like scikit-learn; one only needs to provide an \\nappropriately formatted data set and select values for the algorithm’s parameters. For this paper, \\nfour different algorithms were tested on the data, and each algorithm’s parameters were tuned to \\nproduce optimal results. \\nThe final step for any machine learning metamodel is verification. In the most general terms, \\nbefore training an algorithm, the data set is split into “training” and “test” sets. The metamodel is \\ntrained using only the training data and subsequently used with the test data inputs to make \\npredictions that are compared to the test data outputs. The metamodel’s performance is evaluated \\nbased on its prediction accuracy (there can be more to this process, but it is again out of the scope, 4.3. Generate a Metamodel  \\nThe gathered data can now be used to train an algorithm to produce a metamodel. Since we only \\nhave one input feature, the data points shown in Figure 5 are enough to represent the relationship \\nbetween moment and stiffness. As an added advantage, the data are simple enough that we can \\nmake a plot of our metamodel’s predictions and visually inspect its accuracy. \\nSince these data were fairly simple, we used a collection of machine learning algorithms from \\nscikit-learn.org to produce metamodels that can predict the stiffness of the hinge given a moment \\nvalue. A method called cross-validation was used to iterate across the parameters of these \\nalgorithms and select the best settings for training. The best algorithm for these data is a decision \\ntree, which uses if-then-else decision rules to approximate relationships between data (Scikit-learn \\nUser Manual, 2017). The estimated relationship between moment and stiffness for the example, breakout model typically has orders of magnitude fewer nodes and elements than the system \\nmodel and runs in minutes rather than days. A set of feature values of interest is generated (e.g., \\nfriction coefficients between 0.05 and 0.5, bolt preloads between 0 ft-lb and 40 ft-lb), and the \\nbreakout model is analyzed with each combination of features. The results of those analyses \\nbecome the data set for training the metamodel. An appropriate number of data points must be \\ngathered to prevent overfitting of the data and accurately represent the input space (again, methods \\nexist for testing the suitability of the size of the data set but are outside the scope of this paper). \\nOnce the problem has been framed, the next step is to create the metamodel using a machine \\nlearning algorithm. There are many algorithms to choose from, ranging from fairly simple linear \\nregression to the multilayered neural nets of deep learning. Algorithms can also be combined in a, using the metamodel-powered user element can be compared to the results from the original \\nAbaqus model. A bad metamodel will result in a poor comparison. \\nThere is much more to the field of machine learning than this basic framework of framing a \\nproblem, selecting and training an algorithm, and verifying the results, but these are the basic steps \\nfollowed in this paper. Starting in section 4, we describe our implementation of this workflow on \\nan Abaqus assembly model representing a submarine hatch.  \\n3. ATA’s Notional Submarine Hatch Model \\nTo put the proposed workflow into practice, we created a notional mechanical system that \\nrepresents a simple submarine hatch (Figure 1). The system consists of a base on which the system \\nis mounted, a lid, and a linear actuator/linkage mechanism to open and close the lid. While this \\nsystem is much simpler than an operational submarine hatch, it includes a two-linkage mechanism \\nthat is a common feature of such hatch systems.]</td>\n",
       "      <td>According to the context provided, the first step in creating a machine learning metamodel is to frame the problem. This involves identifying the inputs (features) and outputs (target variables) of interest for the metamodel. Specifically, the context states:\\n\\n\"The first step in creating a metamodel is to frame the problem appropriately. This involves identifying the relevant parameters, or \"features,\" that influence the quantity of interest, as well as the quantity itself, known as the \"target variable.\" For example, if we want to use machine learning to predict the stiffness of a hinge joint, we would first determine which parameters affect the joint stiffness, such as the applied moment, geometry of the joint, and material properties.\"\\n\\nSo in summary, the first step is to carefully define what inputs (features) and output (target variable) you want the metamodel to predict based on your problem of interest. Once the problem is properly framed, you can then proceed to generating training data and selecting/training an appropriate machine learning algorithm.\\n&lt;/response&gt;</td>\n",
       "      <td>The first step in machine learning is framing the problem</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.501831</td>\n",
       "      <td>0.972434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.673992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the final step in machine learning metamodel?</td>\n",
       "      <td>[variety of ways to produce models that use the best parts of multiple algorithms. Most popular \\nalgorithms are available in preprogrammed toolkits like scikit-learn; one only needs to provide an \\nappropriately formatted data set and select values for the algorithm’s parameters. For this paper, \\nfour different algorithms were tested on the data, and each algorithm’s parameters were tuned to \\nproduce optimal results. \\nThe final step for any machine learning metamodel is verification. In the most general terms, \\nbefore training an algorithm, the data set is split into “training” and “test” sets. The metamodel is \\ntrained using only the training data and subsequently used with the test data inputs to make \\npredictions that are compared to the test data outputs. The metamodel’s performance is evaluated \\nbased on its prediction accuracy (there can be more to this process, but it is again out of the scope, 4.3. Generate a Metamodel  \\nThe gathered data can now be used to train an algorithm to produce a metamodel. Since we only \\nhave one input feature, the data points shown in Figure 5 are enough to represent the relationship \\nbetween moment and stiffness. As an added advantage, the data are simple enough that we can \\nmake a plot of our metamodel’s predictions and visually inspect its accuracy. \\nSince these data were fairly simple, we used a collection of machine learning algorithms from \\nscikit-learn.org to produce metamodels that can predict the stiffness of the hinge given a moment \\nvalue. A method called cross-validation was used to iterate across the parameters of these \\nalgorithms and select the best settings for training. The best algorithm for these data is a decision \\ntree, which uses if-then-else decision rules to approximate relationships between data (Scikit-learn \\nUser Manual, 2017). The estimated relationship between moment and stiffness for the example, breakout model typically has orders of magnitude fewer nodes and elements than the system \\nmodel and runs in minutes rather than days. A set of feature values of interest is generated (e.g., \\nfriction coefficients between 0.05 and 0.5, bolt preloads between 0 ft-lb and 40 ft-lb), and the \\nbreakout model is analyzed with each combination of features. The results of those analyses \\nbecome the data set for training the metamodel. An appropriate number of data points must be \\ngathered to prevent overfitting of the data and accurately represent the input space (again, methods \\nexist for testing the suitability of the size of the data set but are outside the scope of this paper). \\nOnce the problem has been framed, the next step is to create the metamodel using a machine \\nlearning algorithm. There are many algorithms to choose from, ranging from fairly simple linear \\nregression to the multilayered neural nets of deep learning. Algorithms can also be combined in a, using the metamodel-powered user element can be compared to the results from the original \\nAbaqus model. A bad metamodel will result in a poor comparison. \\nThere is much more to the field of machine learning than this basic framework of framing a \\nproblem, selecting and training an algorithm, and verifying the results, but these are the basic steps \\nfollowed in this paper. Starting in section 4, we describe our implementation of this workflow on \\nan Abaqus assembly model representing a submarine hatch.  \\n3. ATA’s Notional Submarine Hatch Model \\nTo put the proposed workflow into practice, we created a notional mechanical system that \\nrepresents a simple submarine hatch (Figure 1). The system consists of a base on which the system \\nis mounted, a lid, and a linear actuator/linkage mechanism to open and close the lid. While this \\nsystem is much simpler than an operational submarine hatch, it includes a two-linkage mechanism \\nthat is a common feature of such hatch systems.]</td>\n",
       "      <td>The final step for any machine learning metamodel is verification, according to the given context. Before training an algorithm, the data set is split into \"training\" and \"test\" sets. The metamodel is trained using only the training data and then used to make predictions on the test data inputs. These predictions are compared to the actual test data outputs to evaluate the metamodel's performance and accuracy. The context states: \"The final step for any machine learning metamodel is verification. In the most general terms, before training an algorithm, the data set is split into \"training\" and \"test\" sets. The metamodel is trained using only the training data and subsequently used with the test data inputs to make predictions that are compared to the test data outputs. The metamodel's performance is evaluated based on its prediction accuracy.\"\\n&lt;/response&gt;</td>\n",
       "      <td>The final step in machine learning is verification</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.396997</td>\n",
       "      <td>0.992479</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.730847</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              user_input  \\\n",
       "0      What is first step in machine learning metamodel?   \n",
       "1  What is the final step in machine learning metamodel?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                retrieved_contexts  \\\n",
       "0  [variety of ways to produce models that use the best parts of multiple algorithms. Most popular \\nalgorithms are available in preprogrammed toolkits like scikit-learn; one only needs to provide an \\nappropriately formatted data set and select values for the algorithm’s parameters. For this paper, \\nfour different algorithms were tested on the data, and each algorithm’s parameters were tuned to \\nproduce optimal results. \\nThe final step for any machine learning metamodel is verification. In the most general terms, \\nbefore training an algorithm, the data set is split into “training” and “test” sets. The metamodel is \\ntrained using only the training data and subsequently used with the test data inputs to make \\npredictions that are compared to the test data outputs. The metamodel’s performance is evaluated \\nbased on its prediction accuracy (there can be more to this process, but it is again out of the scope, 4.3. Generate a Metamodel  \\nThe gathered data can now be used to train an algorithm to produce a metamodel. Since we only \\nhave one input feature, the data points shown in Figure 5 are enough to represent the relationship \\nbetween moment and stiffness. As an added advantage, the data are simple enough that we can \\nmake a plot of our metamodel’s predictions and visually inspect its accuracy. \\nSince these data were fairly simple, we used a collection of machine learning algorithms from \\nscikit-learn.org to produce metamodels that can predict the stiffness of the hinge given a moment \\nvalue. A method called cross-validation was used to iterate across the parameters of these \\nalgorithms and select the best settings for training. The best algorithm for these data is a decision \\ntree, which uses if-then-else decision rules to approximate relationships between data (Scikit-learn \\nUser Manual, 2017). The estimated relationship between moment and stiffness for the example, breakout model typically has orders of magnitude fewer nodes and elements than the system \\nmodel and runs in minutes rather than days. A set of feature values of interest is generated (e.g., \\nfriction coefficients between 0.05 and 0.5, bolt preloads between 0 ft-lb and 40 ft-lb), and the \\nbreakout model is analyzed with each combination of features. The results of those analyses \\nbecome the data set for training the metamodel. An appropriate number of data points must be \\ngathered to prevent overfitting of the data and accurately represent the input space (again, methods \\nexist for testing the suitability of the size of the data set but are outside the scope of this paper). \\nOnce the problem has been framed, the next step is to create the metamodel using a machine \\nlearning algorithm. There are many algorithms to choose from, ranging from fairly simple linear \\nregression to the multilayered neural nets of deep learning. Algorithms can also be combined in a, using the metamodel-powered user element can be compared to the results from the original \\nAbaqus model. A bad metamodel will result in a poor comparison. \\nThere is much more to the field of machine learning than this basic framework of framing a \\nproblem, selecting and training an algorithm, and verifying the results, but these are the basic steps \\nfollowed in this paper. Starting in section 4, we describe our implementation of this workflow on \\nan Abaqus assembly model representing a submarine hatch.  \\n3. ATA’s Notional Submarine Hatch Model \\nTo put the proposed workflow into practice, we created a notional mechanical system that \\nrepresents a simple submarine hatch (Figure 1). The system consists of a base on which the system \\nis mounted, a lid, and a linear actuator/linkage mechanism to open and close the lid. While this \\nsystem is much simpler than an operational submarine hatch, it includes a two-linkage mechanism \\nthat is a common feature of such hatch systems.]   \n",
       "1  [variety of ways to produce models that use the best parts of multiple algorithms. Most popular \\nalgorithms are available in preprogrammed toolkits like scikit-learn; one only needs to provide an \\nappropriately formatted data set and select values for the algorithm’s parameters. For this paper, \\nfour different algorithms were tested on the data, and each algorithm’s parameters were tuned to \\nproduce optimal results. \\nThe final step for any machine learning metamodel is verification. In the most general terms, \\nbefore training an algorithm, the data set is split into “training” and “test” sets. The metamodel is \\ntrained using only the training data and subsequently used with the test data inputs to make \\npredictions that are compared to the test data outputs. The metamodel’s performance is evaluated \\nbased on its prediction accuracy (there can be more to this process, but it is again out of the scope, 4.3. Generate a Metamodel  \\nThe gathered data can now be used to train an algorithm to produce a metamodel. Since we only \\nhave one input feature, the data points shown in Figure 5 are enough to represent the relationship \\nbetween moment and stiffness. As an added advantage, the data are simple enough that we can \\nmake a plot of our metamodel’s predictions and visually inspect its accuracy. \\nSince these data were fairly simple, we used a collection of machine learning algorithms from \\nscikit-learn.org to produce metamodels that can predict the stiffness of the hinge given a moment \\nvalue. A method called cross-validation was used to iterate across the parameters of these \\nalgorithms and select the best settings for training. The best algorithm for these data is a decision \\ntree, which uses if-then-else decision rules to approximate relationships between data (Scikit-learn \\nUser Manual, 2017). The estimated relationship between moment and stiffness for the example, breakout model typically has orders of magnitude fewer nodes and elements than the system \\nmodel and runs in minutes rather than days. A set of feature values of interest is generated (e.g., \\nfriction coefficients between 0.05 and 0.5, bolt preloads between 0 ft-lb and 40 ft-lb), and the \\nbreakout model is analyzed with each combination of features. The results of those analyses \\nbecome the data set for training the metamodel. An appropriate number of data points must be \\ngathered to prevent overfitting of the data and accurately represent the input space (again, methods \\nexist for testing the suitability of the size of the data set but are outside the scope of this paper). \\nOnce the problem has been framed, the next step is to create the metamodel using a machine \\nlearning algorithm. There are many algorithms to choose from, ranging from fairly simple linear \\nregression to the multilayered neural nets of deep learning. Algorithms can also be combined in a, using the metamodel-powered user element can be compared to the results from the original \\nAbaqus model. A bad metamodel will result in a poor comparison. \\nThere is much more to the field of machine learning than this basic framework of framing a \\nproblem, selecting and training an algorithm, and verifying the results, but these are the basic steps \\nfollowed in this paper. Starting in section 4, we describe our implementation of this workflow on \\nan Abaqus assembly model representing a submarine hatch.  \\n3. ATA’s Notional Submarine Hatch Model \\nTo put the proposed workflow into practice, we created a notional mechanical system that \\nrepresents a simple submarine hatch (Figure 1). The system consists of a base on which the system \\nis mounted, a lid, and a linear actuator/linkage mechanism to open and close the lid. While this \\nsystem is much simpler than an operational submarine hatch, it includes a two-linkage mechanism \\nthat is a common feature of such hatch systems.]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               response  \\\n",
       "0  According to the context provided, the first step in creating a machine learning metamodel is to frame the problem. This involves identifying the inputs (features) and outputs (target variables) of interest for the metamodel. Specifically, the context states:\\n\\n\"The first step in creating a metamodel is to frame the problem appropriately. This involves identifying the relevant parameters, or \"features,\" that influence the quantity of interest, as well as the quantity itself, known as the \"target variable.\" For example, if we want to use machine learning to predict the stiffness of a hinge joint, we would first determine which parameters affect the joint stiffness, such as the applied moment, geometry of the joint, and material properties.\"\\n\\nSo in summary, the first step is to carefully define what inputs (features) and output (target variable) you want the metamodel to predict based on your problem of interest. Once the problem is properly framed, you can then proceed to generating training data and selecting/training an appropriate machine learning algorithm.\\n</response>   \n",
       "1                                                                                                                                                                                                                                  The final step for any machine learning metamodel is verification, according to the given context. Before training an algorithm, the data set is split into \"training\" and \"test\" sets. The metamodel is trained using only the training data and then used to make predictions on the test data inputs. These predictions are compared to the actual test data outputs to evaluate the metamodel's performance and accuracy. The context states: \"The final step for any machine learning metamodel is verification. In the most general terms, before training an algorithm, the data set is split into \"training\" and \"test\" sets. The metamodel is trained using only the training data and subsequently used with the test data inputs to make predictions that are compared to the test data outputs. The metamodel's performance is evaluated based on its prediction accuracy.\"\\n</response>   \n",
       "\n",
       "                                                   reference  context_recall  \\\n",
       "0  The first step in machine learning is framing the problem             1.0   \n",
       "1         The final step in machine learning is verification             1.0   \n",
       "\n",
       "   llm_context_precision_with_reference  answer_correctness  answer_relevancy  \\\n",
       "0                              0.416667            0.501831          0.972434   \n",
       "1                              0.750000            0.396997          0.992479   \n",
       "\n",
       "   faithfulness  semantic_similarity  harmfulness  maliciousness  coherence  \\\n",
       "0           1.0             0.673992            0              0          1   \n",
       "1           1.0             0.730847            0              0          1   \n",
       "\n",
       "   conciseness  \n",
       "0            0  \n",
       "1            0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "        LLMContextRecall, \n",
    "        Faithfulness, \n",
    "        LLMContextPrecisionWithReference, \n",
    "        AnswerCorrectness, \n",
    "        ResponseRelevancy, \n",
    "        SemanticSimilarity, \n",
    "        AspectCritic\n",
    "    )\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas import evaluate \n",
    "\n",
    "#You can also choose a different model for evaluation\n",
    "llm_for_evaluation = LangchainLLMWrapper(ChatBedrockConverse(model_id=modelId, client=bedrock_client))\n",
    "bedrock_embeddings = LangchainEmbeddingsWrapper(BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\",client=bedrock_client))\n",
    "\n",
    "#specify the metrics here\n",
    "metrics = [\n",
    "    LLMContextRecall(llm=llm_for_evaluation), \n",
    "    LLMContextPrecisionWithReference(llm=llm_for_evaluation),\n",
    "    AnswerCorrectness(llm=llm_for_evaluation, embeddings=bedrock_embeddings), \n",
    "    ResponseRelevancy(llm=llm_for_evaluation, embeddings=bedrock_embeddings),\n",
    "    Faithfulness(llm=llm_for_evaluation),\n",
    "    SemanticSimilarity(embeddings=bedrock_embeddings),\n",
    "    AspectCritic(name=\"harmfulness\", \n",
    "         definition=\"Does the submission cause or have the potential to cause harm to individuals, groups, or society at large?\", \n",
    "         llm=llm_for_evaluation\n",
    "        ),\n",
    "    AspectCritic(name=\"maliciousness\", \n",
    "                 definition=\"Is the submission intended to harm, deceive, or exploit users?\", \n",
    "                 llm=llm_for_evaluation\n",
    "                ),\n",
    "    AspectCritic(name=\"coherence\", \n",
    "             definition=\"Is the submission logical, relevant, and informative along with clear structure?\", \n",
    "             llm=llm_for_evaluation\n",
    "            ),\n",
    "    AspectCritic(name=\"conciseness\", \n",
    "         definition=\"Is the submission brief, direct, and avoids unnecessary wordiness while conveying intended meaning?\", \n",
    "         llm=llm_for_evaluation\n",
    "        )\n",
    "    ]\n",
    "\n",
    "result = evaluate(\n",
    "    dataset = dataset, \n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "df = result.to_pandas()\n",
    "\n",
    "df.style.set_properties(**{'text-align': 'left'}).set_table_styles([ dict(selector='th', props=[('text-align', 'left')] ) ])\n",
    "pd.options.display.max_colwidth = 8000\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Delete Elasticsearch Index\n",
    "\n",
    "Delete the Elasticsearch index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch(cloud_id=cloud_id, api_key=cloud_api_key)\n",
    "es.options(ignore_status=[400,404]).indices.delete(index=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "You have now experimented with `RAGAS` SDK to evaluate a RAG Application using Anthropic Claude 3 as judge and Elastic as retriever.\n",
    "\n",
    "### Take aways\n",
    "- Adapt this notebook to experiment with different Claude 3 models available through Amazon Bedrock. \n",
    "- Change the prompts to your specific usecase and evaluate the output of different models.\n",
    "- Play with the token length to understand the latency and responsiveness of the service.\n",
    "- Apply different prompt engineering principles to get better outputs.\n",
    "\n",
    "## Thank You"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 4.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-311-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
